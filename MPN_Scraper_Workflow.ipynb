{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bded9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./env/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in ./env/lib/python3.9/site-packages (3.1.5)\n",
      "Requirement already satisfied: beautifulsoup4 in ./env/lib/python3.9/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: selenium in ./env/lib/python3.9/site-packages (4.28.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./env/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.9/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: et-xmlfile in ./env/lib/python3.9/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./env/lib/python3.9/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.9/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.9/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.9/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.9/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: trio~=0.17 in ./env/lib/python3.9/site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./env/lib/python3.9/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in ./env/lib/python3.9/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in ./env/lib/python3.9/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in ./env/lib/python3.9/site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in ./env/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in ./env/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./env/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in ./env/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./env/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in ./env/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./env/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install pandas openpyxl beautifulsoup4 requests selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.avantorsciences.com/us/en/product/28504773/deep-freeze-label\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "class Product:\n",
    "    def __init__(self, mpn, product_title=None, price=None, dimensions=None, packaging=None, oum=None):\n",
    "        self.mpn = mpn\n",
    "        self.product_title = product_title\n",
    "        self.price = price\n",
    "        self.dimensions = dimensions\n",
    "        self.packaging = packaging\n",
    "        self.oum = oum\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Product(MPN={self.mpn}, Product_Title={self.product_title}, Price={self.price}, Dimensions={self.dimensions}, Packaging={self.packaging}, OUM={self.oum})\"\n",
    "    \n",
    "def convert_excel_to_csv(input_excel_file, output_csv_file):\n",
    "    df = pd.read_excel(input_excel_file)\n",
    "    df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "def read_mpn_from_csv(file_path):\n",
    "    products = []\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip header row if present\n",
    "        for row in reader:\n",
    "            products.append(Product(mpn=row[0]))\n",
    "    return products\n",
    "\n",
    "def scrape_price_for_mpn_raw(mpn):\n",
    "    url = f\"https://example.com/search?q={mpn}\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        price_element = soup.find('span', class_='price')  # Update with actual structure\n",
    "        if not price_element:\n",
    "            print(f\"Price element not found for MPN {mpn}\")\n",
    "            return None\n",
    "        price = price_element.text.strip()\n",
    "        return price\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {mpn}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def scrape_prices(products):\n",
    "    for product in products:\n",
    "        product.price = scrape_price_for_mpn_selenium(product.mpn)\n",
    "\n",
    "def write_prices_to_csv(products, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"MPN\", \"Price\"])\n",
    "        for product in products:\n",
    "            writer.writerow([product.mpn, product.price])\n",
    "\n",
    "def write_prices_to_excel(products, output_file):\n",
    "    data = [{\"MPN\": product.mpn, \"Price\": product.price} for product in products]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "def process_product(product, mpn):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bfeb687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.avantorsciences.com/us/en/product/28504773/deep-freeze-label\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FOUND: \n",
      "807656001548\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "def scrape_price_for_mpn_ga_international(mpn):\n",
    "    \"\"\"\n",
    "    Uses Selenium to find the search bar, enter the MPN, and select an item from the search results.\n",
    "    \"\"\"\n",
    "    mpn = str(mpn)\n",
    "    # Replace with the URL of the website you are scraping\n",
    "    url = \"https://www.avantorsciences.com\"\n",
    "    \n",
    "    # Path to your WebDriver executable\n",
    "    driver_path = \"/chromedriver\"  # Replace with the actual path to your WebDriver\n",
    "    \n",
    "    # Initialize the WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('--headless')  # Run browser in headless mode\n",
    "    options.add_argument('--disable-gpu')  # Disable GPU for headless\n",
    "    options.add_argument('--no-sandbox')\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the website\n",
    "        driver.get(url+\"/us/en/\")\n",
    "        \n",
    "        # Wait for the search bar to load\n",
    "        wait = WebDriverWait(driver, timeout=10, poll_frequency=.2,ignored_exceptions=ignored_exceptions)\n",
    "        search_bar = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"input\")))  # Replace `name=\"search\"` with the actual locator\n",
    "        \n",
    "        # Enter the MPN into the search bar\n",
    "        search_bar.clear()\n",
    "        search_bar.send_keys(mpn)\n",
    "        search_bar.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # Wait for the search results to load\n",
    "        WebDriverWait(driver=driver, timeout=10, ignored_exceptions=ignored_exceptions).until(expected_conditions.presence_of_element_located((By.CLASS_NAME, \"cx-product-search-list\")))\n",
    "        \n",
    "        \n",
    "        extension = driver.find_element(By.CLASS_NAME, \"cx-product-name\").get_attribute('href')  # Replace with the actual class name\n",
    "        print(extension)\n",
    "        # s = randint(1,10)\n",
    "        # time.sleep(s)\n",
    "        \n",
    "        # Go to product page\n",
    "        driver.get(extension)\n",
    "        # time.sleep(10)\n",
    "        table_list = []\n",
    "        #Wait for product page to load\n",
    "        table_list = wait.until(EC.presence_of_all_elements_located(((By.TAG_NAME, \"app-avtr-product-variant-table\"))))\n",
    "        \n",
    "        # Go through multiple product tables and search for MPN match\n",
    "        products = []\n",
    "        for table in table_list:\n",
    "            table_soup = BeautifulSoup(table.get_attribute('innerHTML'), \"html.parser\")\n",
    "            products = table_soup.find_all(class_=\"item item-container spec-border\")\n",
    "            for product in products:\n",
    "                supplier_num = str(product.find_all(title=\"Supplier #\")[0].text).replace(\" \",\"\")\n",
    "                if supplier_num == mpn:\n",
    "                    print('FOUND: \\n' + mpn)\n",
    "                    process_product(product, supplier_num)\n",
    "                    \n",
    "                    return\n",
    "\n",
    "        # Extract the price\n",
    "        # price_element = driver.find_element(By.CLASS_NAME, \"price\")  # Replace with the actual class for price\n",
    "        # price = price_element.text.strip()\n",
    "        # return price\n",
    "    except Exception as e:\n",
    "        print(f\"Error with MPN {mpn}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "temp = \"807656001548\"\n",
    "soup = scrape_price_for_mpn_ga_international(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81332512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define input and output file paths\n",
    "# input_excel_file = \"mpns.xlsx\"  # Replace with your input Excel file\n",
    "# temp_csv_file = \"mpns.csv\"\n",
    "# output_csv_file = \"prices.csv\"\n",
    "# output_excel_file = \"prices.xlsx\"\n",
    "\n",
    "# # Step 1: Convert Excel to CSV\n",
    "# convert_excel_to_csv(input_excel_file, temp_csv_file)\n",
    "# print(\"Excel converted to CSV.\")\n",
    "\n",
    "# # Step 2: Read MPNs from CSV\n",
    "# products = read_mpn_from_csv(temp_csv_file)\n",
    "# print(\"Products read from CSV:\", products)\n",
    "\n",
    "# # Step 3: Scrape Prices\n",
    "# scrape_prices(products)\n",
    "# print(\"Prices scraped:\", products)\n",
    "\n",
    "# # Step 4: Write to CSV\n",
    "# write_prices_to_csv(products, output_csv_file)\n",
    "# print(f\"Prices written to {output_csv_file}\")\n",
    "\n",
    "# # Step 5: Write to Excel\n",
    "# write_prices_to_excel(products, output_excel_file)\n",
    "# print(f\"Prices written to {output_excel_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
